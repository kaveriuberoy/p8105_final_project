---
title: "Data Cleaning"
output: github_document
date: "2025-11-16"
---



```{r}
library(tidyverse)

# all demographic data. currently selecting for name, fips, lat and long, race, population 2019, deaths by homicide, life expectancy, fatal police shootings 2017,2018,2019, 2020, average income, dem/gop for 2016, 2020, poverty rate, children in poverty, 80th and 20th percentile incomes, violent crime rate. This one contains everything. I've divided them into subcategories, so that if someone wants to use them for a particular analysis, they can select from it easily to create some mini dfs. 

# made lots of changes to naming within the df so it could be easily joined with nyt data. 

counties_demo_df = 
  read_csv(file = "./data/counties.csv") |>
  janitor::clean_names() |>
  select(name, fips, state, longitude_deg, latitude_deg, 
         # race for each county 
         race_non_hispanic_white_alone_male,race_non_hispanic_white_alone_female,
         race_black_alone_male,race_black_alone_female,
         race_asian_alone_male,race_asian_alone_female,
         race_hispanic_male, race_hispanic_female,
         # overall population
         population_2019,
         # firearm and police shooting info
         deaths_firearm_suicides,deaths_homicides, 
         fatal_police_shootings_total_2017, 
         fatal_police_shootings_unarmed_2017, fatal_police_shootings_firearmed_2017, 
         fatal_police_shootings_total_2018, 
         fatal_police_shootings_unarmed_2018, fatal_police_shootings_firearmed_2018, 
         fatal_police_shootings_total_2019, 
         fatal_police_shootings_unarmed_2017, fatal_police_shootings_firearmed_2019, 
         fatal_police_shootings_total_2020, 
         fatal_police_shootings_unarmed_2017, fatal_police_shootings_firearmed_2020, 
         police_deaths,
         health_violent_crime_rate,
         # income/ poverty related 
         avg_income, 
         poverty_rate,
         health_percent_children_in_poverty,
         health_80th_percentile_income, 
         health_20th_percentile_income, 
         # elections
         elections_2016_total, elections_2016_dem, elections_2016_gop,
         elections_2020_total, elections_2020_dem, elections_2020_gop,
         # general health
         life_expectancy, 
         health_percent_smokers
         ) |>
  rename(county = name) |>
  mutate(
    county = sub(" county", "", county, fixed = TRUE), 
    county = sub(" parish", "", county, fixed = TRUE)
    ) |>
  mutate(state = state.name[ match(state, state.abb) ])

# nyt covid data per year, with all the info in them. 
covid_2020_df = 
  read_csv(file = "./data/us-counties-2020.csv") |>
  janitor::clean_names() |>
  mutate(year = 2020)

covid_2021_df = 
  read_csv(file = "./data/us-counties-2021.csv") |>
  janitor::clean_names() |>
  mutate(year = 2021)

covid_2022_df = 
  read_csv(file = "./data/us-counties-2022.csv") |>
  janitor::clean_names() |>
  mutate(year = 2022)

covid_2023_df = 
  read_csv(file = "./data/us-counties-2023.csv") |>
  janitor::clean_names() |>
  mutate(year = 2023)

# nyt masking data, all from july 2020, peak covid, from survey data as well. Divided into high mask use and low mask use columns for simplicity. 

covid_masking_df =
  read_csv(file = "./data/mask-use-by-county.csv") |>
  mutate(
    COUNTYFP = sprintf("%05d", as.numeric(COUNTYFP)),
    high_mask_use = FREQUENTLY + ALWAYS,
    low_mask_use  = NEVER + RARELY + SOMETIMES
  )

# all the covid data with sums per year of cases and deaths per county per year. 

df_covid_per_year =
  bind_rows(covid_2020_df, covid_2021_df, covid_2022_df, covid_2023_df) |>
  group_by(county, state, fips, year) |>
  summarise(
    total_cases = sum(cases, na.rm = TRUE),
    total_deaths = sum(deaths, na.rm = TRUE),
    .groups = "drop"
  ) |>
    pivot_wider(
    names_from = year,
    values_from = c(total_cases, total_deaths),
    names_glue = "{.value}_{year}"
  ) |>
  mutate(fips = sprintf("%05d", as.numeric(fips))) |>
  left_join(
    covid_masking_df |>
      select(COUNTYFP, high_mask_use, low_mask_use),
    by = c("fips" = "COUNTYFP")
  )

# for Evan's analysis : all the COVID data by county, but not with sums/totals, all raw data. Also including masking survey data in here in case. 

df_covid_all_raw =
  bind_rows(covid_2020_df, covid_2021_df, covid_2022_df, covid_2023_df) |>
  pivot_wider(
    id_cols = c(fips, county, state),
    names_from = c(date),
    values_from = c(cases, deaths),
    names_glue = "{date}_{.value}"
  ) |>
  mutate(fips = sprintf("%05d", as.numeric(fips))) |>
  left_join(
    covid_masking_df |>
      select(COUNTYFP, high_mask_use, low_mask_use),
    by = c("fips" = "COUNTYFP")
  )

# covid data joined with counties demographic data. 
# some things counties_demo_df data treats as counties, such as boroughs in nyc and alaska boroughs, not in the nyt data. So just matched whatever we could for now. We can discuss how we want to handle this later. 

df_covid_per_year[["county"]] <- tolower(trimws(df_covid_per_year[["county"]]))

covid_demo_final_df <- counties_demo_df |>
  left_join(
    df_covid_per_year,
    by = c("fips", "county", "state")
  )
saveRDS(covid_demo_final_df, file = "covid_demo_final_df.rds")

```

